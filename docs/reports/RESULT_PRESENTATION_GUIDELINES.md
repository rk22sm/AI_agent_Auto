# Result Presentation Guidelines

## Purpose

This document provides strict guidelines for presenting results after completing tasks, especially when executing slash commands. These guidelines ensure users receive clear, actionable, and concise feedback.

## Core Principles

1. **NEVER complete a task silently.** Users must always see key results.
2. **Be CONCISE in terminal output.** Show summary only - save details to file.
3. **Always provide file path** for detailed results that users can review later.

## Two-Tier Result Strategy

### Tier 1: Concise Terminal Output (REQUIRED)
Show in terminal immediately:
- âœ“ Overall status and key metrics (1-3 lines)
- âœ“ Most important findings (top 3 max)
- âœ“ Critical recommendations (top 3 max)
- âœ“ File path to detailed report

### Tier 2: Detailed File Report (REQUIRED)
Save to file for user review:
- âœ“ Complete analysis and breakdown
- âœ“ All findings and metrics
- âœ“ Comprehensive recommendations
- âœ“ Charts, graphs, and visualizations
- âœ“ Full context and explanations

### When to Use This Strategy

Apply two-tier presentation after:
- âœ“ Executing any slash command (`/auto-analyze`, `/quality-check`, etc.)
- âœ“ Completing autonomous analysis or quality checks
- âœ“ Delegating to specialized agents that produce findings
- âœ“ Running background tasks that generate insights
- âœ“ Any significant task that produces detailed results

## Standard Result Format

### Concise Terminal Output Template

```
âœ“ [TASK NAME] Complete - Quality: XX/100

Key Results:
â€¢ [Most important finding #1]
â€¢ [Most important finding #2]
â€¢ [Most important finding #3]

Top Recommendations:
1. [HIGH] [Critical action needed]
2. [MED]  [Important improvement]
3. [LOW]  [Optional enhancement]

ğŸ“„ Full report: .claude/reports/[task-name]-YYYY-MM-DD.md
â± Completed in X.X minutes
```

**Length Limit**: Maximum 15-20 lines in terminal

### Detailed File Report Template

Saved to `.claude/reports/[task-name]-YYYY-MM-DD.md`:

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  [TASK NAME] DETAILED REPORT
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Generated: YYYY-MM-DD HH:MM:SS

â”Œâ”€ [Section Title] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [Complete content with all details]                   â”‚
â”‚ [All metrics, charts, and analysis]                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ [Another Section] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [Full breakdown]                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[All remaining sections with comprehensive information]

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Formatting Rules

1. **Header Line**: Use `â•` for top and bottom borders (55 characters wide)
2. **Section Boxes**: Use `â”Œâ”€â”â””â”€â”˜â”‚` for box drawing (55 characters wide)
3. **Alignment**: Left-align content with 1 space padding inside boxes
4. **Spacing**: Single blank line between sections
5. **Symbols**: Use âœ“, âœ—, âš , â†‘, â†“, â†’ for status indicators
6. **Priority Tags**: Use [HIGH], [MED], [LOW] for recommendations

### Required Sections

Every **terminal output** MUST include:
1. **Status Line**: Task name, completion status, key metric
2. **Key Results**: Top 3 most important findings only
3. **Top Recommendations**: Top 3 actions only
4. **File Path**: Where to find detailed report
5. **Execution Time**: How long it took

Every **file report** MUST include:
1. **Header**: Task name, timestamp, metadata
2. **Complete Results**: All metrics and findings
3. **Detailed Breakdown**: Full analysis by category
4. **All Recommendations**: Prioritized and explained
5. **Charts/Visualizations**: When applicable
6. **Footer**: Summary and next steps

## Command-Specific Formats

### /auto-analyze Results

**Terminal Output** (concise):
```
âœ“ Auto-Analyze Complete - Quality: 88/100

Key Findings:
â€¢ Python/FastAPI project, 127 files analyzed
â€¢ 4 failing tests in auth module
â€¢ 12 functions missing docstrings

Top Recommendations:
1. [HIGH] Fix failing auth tests â†’ +4 quality points
2. [MED]  Add docstrings to public APIs
3. [MED]  Refactor high-complexity functions

ğŸ“„ Full report: .claude/reports/auto-analyze-2025-10-21.md
â± Completed in 2.3 minutes
```

**File Report** (detailed):
Save to `.claude/reports/auto-analyze-YYYY-MM-DD.md` with:
1. Project Context (full details)
2. Quality Assessment (complete breakdown)
3. Key Findings (all strengths and issues)
4. Recommendations (all, prioritized)
5. Pattern Learning Status
6. Metadata and charts

### /quality-check Results

**Terminal Output** (concise):
```
âœ“ Quality Check Complete - Score: 88/100 (â†‘ +5)

Quality Breakdown:
â€¢ Tests: 26/30 (45 passed, 2 failed)
â€¢ Standards: 18/25 (18 violations fixed)
â€¢ Documentation: 19/20 (97% complete)

Auto-Fixed:
â€¢ 12 style violations, 3 docstrings added

Top Issues:
1. [HIGH] 2 failing tests in auth module
2. [MED]  6 style violations need manual review

ğŸ“„ Full report: .claude/reports/quality-check-2025-10-21.md
â± Completed in 1.8 minutes
```

**File Report** (detailed):
Save to `.claude/reports/quality-check-YYYY-MM-DD.md` with complete breakdown, all auto-fix actions, all remaining issues, trend analysis.

### /learn-patterns Results

**Terminal Output** (concise):
```
âœ“ Pattern Learning Initialized

Project Detected:
â€¢ Python/FastAPI project, 127 files
â€¢ 5 initial patterns identified
â€¢ Database created: .claude-patterns/

Next Steps:
1. Run /auto-analyze to establish quality baseline
2. Run /quality-check to assess current state
3. Start working - system learns automatically!

ğŸ“„ Full report: .claude/reports/learn-patterns-2025-10-21.md
â± Completed in 0.8 minutes
```

**File Report** (detailed):
Save to `.claude/reports/learn-patterns-YYYY-MM-DD.md` with complete project analysis, all detected patterns, baseline metrics, framework details.

### /performance-report Results

**Terminal Output** (concise):
```
âœ“ Performance Report Generated

Executive Summary:
â€¢ 47 patterns learned, 67% reuse rate
â€¢ Quality trend: â†‘ +18% (30 days)
â€¢ Top skill: pattern-learning (92% success)

Top Recommendations:
1. [HIGH] Use pattern-learning more often â†’ +12 points avg
2. [HIGH] Run quality-controller before completion â†’ +13 points
3. [MED]  Delegate testing to test-engineer â†’ 91% success

ğŸ“„ Full report: .claude/reports/performance-2025-10-21.md
   Includes: Charts, trends, complete metrics
â± Completed in 0.5 minutes
```

**File Report** (detailed):
Save to `.claude/reports/performance-YYYY-MM-DD.md` with complete dashboard, ASCII charts, all metrics, trend analysis, skill/agent performance details.

### /recommend Results

**Terminal Output** (concise):
```
âœ“ Recommendations Ready - Task: "Refactor auth module"

Recommended Approach (92% confidence):
â€¢ Expected Quality: 94/100 (+19 from baseline)
â€¢ Estimated Time: 12-15 minutes
â€¢ Skills: code-analysis, quality-standards, pattern-learning
â€¢ Agents: code-analyzer, quality-controller

Alternatives:
â€¢ Minimal (10 min, quality 82) - faster but lower quality
â€¢ Comprehensive (20 min, quality 91) - slower but thorough

Risk Level: MEDIUM - Legacy code complexity
â†’ Mitigation: Use code-analyzer first, add 5 min buffer

ğŸ“„ Full report: .claude/reports/recommend-2025-10-21.md
   Includes: Detailed comparisons, risk analysis, insights
```

**File Report** (detailed):
Save to `.claude/reports/recommend-YYYY-MM-DD.md` with complete approach details, all alternatives, full risk assessment, confidence analysis, skill synergies.

## Visual Elements

### Status Indicators

- âœ“ Success, completed, passing
- âœ— Failure, missing, not done
- âš  Warning, needs attention
- â†’ Result, outcome, leads to
- â†‘ Improvement, increase
- â†“ Decline, decrease

### Progress Bars (ASCII)

For skill performance or metrics visualization:
```
skill-name          â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 92% (12 tasks)
another-skill       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘ 88% (15 tasks)
```

Use â–ˆ for filled portions, â–‘ for unfilled (12 characters total width)

### Trend Charts (ASCII)

For quality over time:
```
100 â”‚                            â—
 90 â”‚        â—â”€â”€â—â”€â”€â—        â—â”€â”€â—â”€â”˜
 80 â”‚    â—â”€â”€â”˜              â”Œâ”˜
 70 â”‚â—â”€â”€â”€â”˜                 â”‚ (threshold)
 60 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Week 1  Week 2  Week 3  Week 4
```

Use â— for data points, â”€â”‚â”Œâ”â””â”˜ for lines

### Priority Tags

Recommendations must be tagged:
- [HIGH] - Critical, immediate action needed
- [MED] - Important, should address soon
- [LOW] - Nice to have, address when time permits

## Content Guidelines

### Be Specific

âŒ Bad: "Tests are mostly passing"
âœ“ Good: "45 passed, 2 failed | 88% coverage"

âŒ Bad: "Quality improved"
âœ“ Good: "Quality improved from 83 â†’ 88 (+5 points)"

âŒ Bad: "Some issues found"
âœ“ Good: "â€¢ 4 failing tests in auth module
         â€¢ 12 functions missing docstrings"

### Be Actionable

Every recommendation should include:
- What to do
- Why it matters (impact/benefit)
- How to do it (if not obvious)

Example:
```
1. [HIGH] Fix failing auth tests
   â†’ Expected +4 quality points
   â†’ Affects: user login and token refresh
```

### Be Concise Yet Comprehensive

- Focus on important results, not verbose explanations
- Use bullet points for lists
- Group related items
- Omit unnecessary details
- Include enough context to understand findings

### Show Impact

Always quantify impact when possible:
- Quality score changes: "+5 points"
- Time savings: "25% faster"
- Success rates: "92% success rate"
- Comparisons: "from 83 â†’ 88"

## Anti-Patterns to Avoid

### âŒ Silent Completion

Never:
- Complete without showing results
- Return only status codes or boolean values
- Provide minimal "Done" messages
- Skip presenting findings because task succeeded

### âŒ Too Verbose in Terminal

Never:
- Show 50+ lines of detailed output in terminal
- Include all charts and visualizations in terminal
- Present every single finding in terminal
- Omit the file path to detailed report

### âŒ No Detailed Report File

Never:
- Save only terminal output without detailed file
- Omit file path from terminal output
- Skip creating the report file
- Provide incomplete file reports

### âŒ Vague Information

Never:
- Use ambiguous terms ("some", "mostly", "a few")
- Provide metrics without context
- Give recommendations without expected impact
- Show errors without file/line references

### âŒ Wrong Balance

Never:
- Show too little in terminal (just "Done")
- Show too much in terminal (complete report)
- Create empty or minimal file reports
- Forget to mention where detailed report is saved

## Integration with Orchestrator

The orchestrator agent is responsible for:
1. Executing the command/task
2. Collecting all results from delegated agents
3. **Creating detailed report file** in `.claude/reports/`
4. **Presenting concise summary** to terminal (15-20 lines max)
5. **Including file path** to detailed report

The orchestrator must ALWAYS:
- Save complete results to `.claude/reports/[command]-YYYY-MM-DD.md`
- Show concise summary in terminal (key results + top 3 recommendations)
- Include file path in terminal output
- Keep terminal output under 20 lines

The orchestrator must NEVER:
- Show 50+ lines of detailed results in terminal
- Skip creating the detailed report file
- Omit the file path from terminal output
- Complete silently without any terminal output

## Quality Checklist

Before presenting results, verify:

**Terminal Output:**
- [ ] Concise (15-20 lines maximum)
- [ ] Shows key metric/status on first line
- [ ] Lists top 3 findings only
- [ ] Lists top 3 recommendations only
- [ ] Includes file path to detailed report
- [ ] Shows execution time
- [ ] Uses clear status indicators (âœ“, âš , â†’)

**File Report:**
- [ ] Saved to `.claude/reports/[command]-YYYY-MM-DD.md`
- [ ] Header identifies task and timestamp
- [ ] All metrics and findings included
- [ ] All recommendations prioritized and explained
- [ ] Charts/visualizations when applicable
- [ ] Metadata includes agents, skills, execution time
- [ ] Visual formatting consistent (boxes, alignment)
- [ ] Specific numbers/examples provided (not vague)
- [ ] Impact quantified where possible

## Examples of Good vs. Bad

### âŒ Bad Example #1 (Too Silent)
```
Analysis complete. Quality: 88.
```

### âŒ Bad Example #2 (Too Verbose - 50+ lines in terminal)
```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  AUTO-ANALYZE COMPLETED
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€ Project Context â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Type: Python project with FastAPI framework          â”‚
â”‚ Languages: Python 3.9+                                â”‚
â”‚ Frameworks: FastAPI, SQLAlchemy, Pydantic            â”‚
â”‚ Total Files: 127                                      â”‚
â”‚ [... 40 more lines ...]
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
(User has to scroll through terminal to see everything)

### âœ“ Good Example (Concise Terminal + Detailed File)

**Terminal Output:**
```
âœ“ Auto-Analyze Complete - Quality: 88/100

Key Findings:
â€¢ Python/FastAPI project, 127 files analyzed
â€¢ 4 failing tests in auth module
â€¢ 12 functions missing docstrings

Top Recommendations:
1. [HIGH] Fix failing auth tests â†’ +4 quality points
2. [MED]  Add docstrings to public APIs
3. [MED]  Refactor high-complexity functions

ğŸ“„ Full report: .claude/reports/auto-analyze-2025-10-21.md
â± Completed in 2.3 minutes
```

**File Report** (.claude/reports/auto-analyze-2025-10-21.md):
```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  AUTO-ANALYZE DETAILED REPORT
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Generated: 2025-10-21 14:30:00

â”Œâ”€ Project Context â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Type: Python project with FastAPI framework          â”‚
â”‚ Languages: Python 3.9+                                â”‚
â”‚ Frameworks: FastAPI, SQLAlchemy, Pydantic            â”‚
â”‚ Total Files: 127                                      â”‚
â”‚ [... complete details ...]
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[... all remaining sections with full details ...]
```

## Conclusion

Following these guidelines ensures users receive:
- **Concise terminal output** they can quickly scan (15-20 lines)
- **Detailed file reports** they can review when needed
- **Clear file paths** to find comprehensive information
- **Actionable insights** for next steps
- **Transparency** without overwhelming terminal output

**Remember**:
- Terminal output = Quick summary only (15-20 lines max)
- File report = Complete details with all findings
- Always include file path in terminal output
- Never complete silently, never overwhelm with details
